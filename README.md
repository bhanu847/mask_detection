ğŸ—‚ï¸ Project Structure (and My Step-by-Step Journey ğŸš€)

So hereâ€™s how I approached this entire face mask detection project from scratch â€” from picking a random dataset to running it live with Flask.

ğŸ§© Step 1 â€” Choosing the Dataset

I didnâ€™t use any predefined dataset from Kaggle or local storage â€”
I just went to Roboflow Universe
, searched for "mask detection" datasets, and picked a random one called
Face-mask-vsxay under the workspace â€œdetection-and-segmentationâ€.

It was already labeled for two classes:

with_mask

without_mask

I used Roboflowâ€™s API to download it directly in YOLOv8 format, which saves a lot of manual label conversion headaches.
The short script I used looked like this:

from roboflow import Roboflow

rf = Roboflow(api_key="YOUR_API_KEY")
project = rf.workspace("detection-and-segmentation").project("face-mask-vsxay")
dataset = project.version(2).download("yolov8")
print("Dataset downloaded successfully!")


This automatically created a folder named something like Face-mask-2 that contained images/ and labels/ directories in YOLO format.

ğŸ§¹ Step 2 â€” Preprocessing the Dataset

Once I had the dataset, I wanted to make it clean and consistent before training YOLO.
So I wrote a preprocess.py script that does a few important things:

Resize all images to 640Ã—640 pixels (the standard YOLOv8 input size).

Split the dataset into:

Train (80%)

Validation (15%)

Test (5%)

Augment the training data by flipping some images horizontally â€” this helps YOLO generalize better.

Copy all labels properly so that each image still points to its .txt label.

Generate a data.yaml file that YOLOv8 needs to know where your train/val/test folders are.

Basically, after running:

python preprocess.py


it created a clean folder called dataset_processed/ with this structure:

dataset_processed/
â”œâ”€â”€ images/train
â”œâ”€â”€ images/val
â”œâ”€â”€ images/test
â”œâ”€â”€ labels/train
â”œâ”€â”€ labels/val
â”œâ”€â”€ labels/test
â””â”€â”€ data.yaml


And the data.yaml file looked like this:

train: images/train
val: images/val
test: images/test
names:
  0: with_mask
  1: without_mask


This means YOLO now knows where to find everything and what each class ID represents.

âš™ï¸ Step 3 â€” Training the Detection Model (YOLOv8)

Once my dataset was clean and ready, I jumped into training YOLOv8.
I used the YOLOv8n (nano) model since itâ€™s fast and light â€” perfect for CPU or small GPU setups.

My train_yolo.py looked like this:

from ultralytics import YOLO

model = YOLO("yolov8n.pt")  # pretrained weights
model.train(
    data="dataset_processed/data.yaml",
    epochs=50,
    imgsz=640,
    batch=8,
    project="face_mask_yolo",
    name="run1"
)


Thatâ€™s it! YOLOv8 takes care of the rest.
It logs training progress, saves the best weights, and gives you graphs like loss curves and mAP scores.

After training, the outputs are automatically saved under:

runs/detect/run1/
â”œâ”€â”€ weights/
â”‚   â”œâ”€â”€ best.pt
â”‚   â””â”€â”€ last.pt
â””â”€â”€ results.png


The best.pt model is what I later used for evaluation and deployment.

ğŸ§  Step 4 â€” Training the Classification Model (EfficientNet_B0)

Now, although YOLOv8 already detects mask vs no-mask quite well,
I wanted to add a second stage classifier to make the predictions even more confident.

So I used EfficientNet_B0 (from torchvision.models) â€” a lightweight CNN thatâ€™s great for binary classification tasks.

I trained it separately on cropped face images from the YOLO dataset.
Basically:

Input: single face image

Output: â€œWith Maskâ€ or â€œWithout Maskâ€

Training setup:

from torchvision import models
import torch.nn as nn

model = models.efficientnet_b0(pretrained=True)
model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)


Then I trained it for about 10â€“20 epochs using Adam optimizer and saved the best model as:

models/efficientnet_b0.pth


This classifier is later loaded inside the Flask app to classify cropped YOLO detections more precisely.

ğŸ“Š Step 5 â€” Model Evaluation

For evaluation, I wanted to see how my model actually performs visually, not just by numbers.
So I wrote evaluate.py, which does two main things:

Draws YOLO predictions (bounding boxes + labels + confidence) on validation images and saves them in evaluation_outputs/.

Generates a Confusion Matrix using scikit-learn to see how many predictions were right/wrong.

Example run:

python evaluate.py


It automatically finds the best YOLO weights from the training folder and runs inference on all validation images.

Output:

evaluation_outputs/
â”œâ”€â”€ image1_pred.jpg
â”œâ”€â”€ image2_pred.jpg
â””â”€â”€ confusion_matrix.png


The confusion matrix gives a clear picture of how well the model distinguishes between with_mask and without_mask.

ğŸŒ Step 6 â€” Flask Web App Deployment

Once everything worked, I built a simple Flask web app (app.py) so anyone can test it easily.

Hereâ€™s what happens behind the scenes:

You upload an image on the Flask web UI.

The app loads YOLOv8 (for detection) and EfficientNet_B0 (for classification).

YOLO finds all the faces in the image.

Each detected face is cropped and sent to the EfficientNet model for classification.

The output image (with bounding boxes and mask labels) is displayed right on the page.

To run it:

python app.py


Then visit:

http://127.0.0.1:5000/


Youâ€™ll see a simple upload box â†’ upload an image â†’ get results instantly!

ğŸ“ Final Folder Overview

Hereâ€™s how my project looks after everything is set up:

face-mask-detection/
â”œâ”€â”€ app.py                     # Flask app for inference
â”œâ”€â”€ download_roboflow.py       # Dataset download
â”œâ”€â”€ preprocess.py              # Resize, augment, and split dataset
â”œâ”€â”€ train_yolo.py              # YOLOv8 training script
â”œâ”€â”€ train_classifier.py        # EfficientNet_B0 training script
â”œâ”€â”€ evaluate.py                # Confusion matrix + annotated results
â”‚
â”œâ”€â”€ dataset_processed/         # Clean, ready-to-train dataset
â”œâ”€â”€ models/                    # Trained model weights
â”‚   â”œâ”€â”€ yolov8_best.pt
â”‚   â””â”€â”€ efficientnet_b0.pth
â”œâ”€â”€ runs/detect/run1/          # YOLOv8 training logs and weights
â”œâ”€â”€ evaluation_outputs/        # Confusion matrix + visual results
â””â”€â”€ static/uploads/            # Uploaded test images (via Flask)

âœ… Summary â€” What I Did from Start to End

Picked a random Roboflow dataset (Face-mask-vsxay)

Downloaded it in YOLOv8 format using Roboflow API

Preprocessed the data â€” resized, augmented, and split

Trained YOLOv8 for mask detection

Trained EfficientNet_B0 for fine-grained mask classification

Evaluated the models â€” confusion matrix + annotated images

Deployed the models together in a Flask app

Tested locally by uploading random face images ğŸ‰
